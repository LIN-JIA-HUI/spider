# GPU爬蟲系統更新功能需求文件

## 1. 專案概述

### 1.1 背景

現有的 GPU 爬蟲系統已開發完成，可以從 techpowerup.com 網站爬取 GPU 產品、規格及相關評測資料。目前系統能夠爬取產品列表、產品詳情、主板評測等資訊，並將資料存儲到 SQL Server 資料庫。但目前缺乏評測資料的更新機制和相關 URL 的儲存功能，導致無法有效追蹤和更新評測內容。

### 1.2 目標

1. 為系統增加評測 URL 的存儲功能，以便後續進行高效更新
2. 開發評測資料的全量更新和增量更新功能
3. 提供 API 端點以支持從前端觸發更新操作
4. 優化爬蟲策略，避免因頻繁請求被網站封鎖

## 2. 系統架構和資料庫結構

### 2.1 現有系統架構

- **爬蟲主類**: `GPUScraper` - 負責管理爬取流程和資料處理
- **解析器**: `GPUParser` - 負責頁面解析和資料提取
- **資料庫管理**: `Database` - 負責資料庫操作
- **存儲管理**: `StorageManager` - 負責資料存儲邏輯
- **狀態管理**: `ScrapeState` - 負責管理爬蟲狀態
- **防爬蟲機制**: `AntiCrawl` - 負責實現防爬蟲策略

### 2.2 資料庫結構變更需求

需要對 `C_Product_Review` 表進行以下修改:

```sql
-- 在 C_Product_Review 表中添加兩個欄位
ALTER TABLE dbo.C_Product_Review ADD F_Main_Review_URL NVARCHAR(500);
ALTER TABLE dbo.C_Product_Review ADD F_Page_URL NVARCHAR(500);
```

欄位說明:
- `F_Main_Review_URL`: 存儲主評測頁面 URL (如 https://www.techpowerup.com/review/asus-tuf-rtx-50/)
- `F_Page_URL`: 存儲具體子頁面的 URL (如 https://www.techpowerup.com/review/asus-tuf-rtx-50/3-circuit-board-analysis.html)

### 2.3 現有資料表結構關聯

- `C_Product`: 存儲產品基本資訊，含 `F_SeqNo`(主鍵), `F_Product`(產品名稱), `F_UpdateTime`(更新時間)等欄位
- `C_Product_Review`: 存儲評測資料，含 `F_Master_ID`(關聯產品ID), `F_Type`(評測類型), `F_Title`(標題), `F_Desc`(內容)等欄位
- `C_Specs_Database`: 存儲規格資料，含 `F_Master_ID`(關聯產品ID), `F_Type`(規格類型), `F_Name`(規格名稱), `F_Value`(規格值)等欄位

## 3. 功能需求

### 3.1 URL 資料爬取與存儲

#### 3.1.1 評測 URL 爬取功能

開發一個獨立函數，用於爬取並存儲評測 URL，不涉及已有產品資料的修改:

1. 從 techpowerup.com 網站的 Popular 頁面獲取 GPU 產品列表
2. 進入每個產品的詳情頁面
3. 查找 id="boards" 區域，獲取有評測圖標的 URL
4. 建立產品 ID 與評測 URL 的對應關係
5. 將主評測 URL 存入資料庫

#### 3.1.2 子頁面 URL 爬取功能

進一步開發功能，用於爬取評測的子頁面 URL:

1. 根據主評測 URL 訪問評測頁面
2. 解析下拉選單中的各子頁面類型 (如 "Circuit Board Analysis", "Pictures & Teardown" 等)
3. 生成子頁面 URL 並與 `F_Type` 進行匹配
4. 將子頁面 URL 存入資料庫

### 3.2 評測資料全量更新

#### 3.2.1 全量更新流程

開發一個全量更新功能，重新爬取所有評測資料:

1. 對每個產品的評測進行訪問和解析
2. 使用優化過的 parser.py 解析頁面內容
3. 更新評測內容和相關規格資料
4. 更新資料庫中的時間戳

#### 3.2.2 解析規則更新

確保最新的解析規則能正確應用於所有評測內容，並更新以下資料:

1. 評測文本內容
2. 溫度和噪音數據
3. 超頻和功耗限制資料
4. 電路板分析資料
5. 其他相關規格參數

### 3.3 評測資料增量更新

#### 3.3.1 更新檢查機制

開發增量更新機制，只更新有變化的評測:

1. 獲取資料庫中所有有評測 URL 的記錄
2. 訪問每個主評測 URL，獲取 Posted 日期
3. 將 Posted 日期與資料庫中的 `F_UpdateTime` 進行比較
4. 如日期不一致，標記為需要更新

#### 3.3.2 增量更新流程

對需要更新的評測執行更新操作:

1. 重新爬取主評測頁面和相關子頁面
2. 使用與全量更新相同的解析邏輯更新內容
3. 更新資料庫中的評測內容和相關規格
4. 更新 `F_UpdateTime` 欄位

### 3.4 API 端點開發

#### 3.4.1 全量更新 API

開發全量更新 API 端點:

```
GET /run-scraper?mode=full
```

- 功能: 觸發所有評測資料的全量更新
- 參數: `mode=full` 指定全量更新模式
- 回應: 返回更新任務狀態 (如啟動成功)

#### 3.4.2 增量更新 API

開發增量更新 API 端點:

```
GET /run-scraper?mode=incremental
```

- 功能: 觸發評測資料的增量更新
- 參數: `mode=incremental` 指定增量更新模式
- 回應: 返回更新任務狀態

#### 3.4.3 更新狀態查詢 API

優化現有的狀態查詢 API:

```
GET /status
```

- 功能: 查詢更新任務的執行狀態
- 回應: 返回當前更新任務的狀態和相關統計資訊

## 4. 非功能需求

### 4.1 性能要求

1. 全量更新應能在 24 小時內完成所有資料的更新
2. 增量更新應能在 2 小時內檢查所有評測並更新變化的內容
3. API 回應時間應在 500ms 以內

### 4.2 可靠性要求

1. 系統應能處理網絡中斷或請求失敗的情況
2. 部分評測更新失敗不應影響其他評測的處理
3. 系統應保留上次成功更新的時間戳，以便在失敗後能從斷點續爬

### 4.3 安全與防爬蟲策略

1. 請求間隔應隨機化，避免固定頻率被識別
2. 應實現指數退避算法處理請求失敗情況
3. 限制並發請求數量，避免短時間內發送過多請求
4. 使用隨機 User-Agent 和其他頭部信息

## 5. 實施計劃

### 5.1 階段規劃

1. **階段 1**: 資料庫結構更新和 URL 爬取功能開發
   - 新增資料表欄位
   - 開發評測 URL 爬取功能
   - 開發子頁面 URL 爬取功能

2. **階段 2**: 全量更新功能開發
   - 實現全量更新邏輯
   - 優化解析規則和存儲流程
   - 開發全量更新 API 端點

3. **階段 3**: 增量更新功能開發
   - 實現更新檢查機制
   - 開發增量更新邏輯
   - 開發增量更新 API 端點

4. **階段 4**: 測試與優化
   - 進行功能測試和壓力測試
   - 優化效能和可靠性
   - 完善錯誤處理和日誌記錄

### 5.2 優先級

1. 資料庫結構更新和 URL 爬取功能 - **高優先級**
2. 全量更新功能開發 - **高優先級**
3. 增量更新功能開發 - **中優先級**
4. API 端點開發 - **中優先級**
5. 測試與優化 - **低優先級**

## 6. 技術考量

### 6.1 開發環境

- Python 3.10+
- aiohttp 庫用於非同步 HTTP 請求
- Beautiful Soup 用於 HTML 解析
- pyodbc 用於資料庫操作
- FastAPI 用於 API 開發

### 6.2 代碼組織

- 新增 `update_manager.py` 模組，專門處理更新相關邏輯
- 擴展 `database.py` 添加 URL 存儲和查詢功能
- 擴展 `parsers.py` 優化評測頁面解析邏輯
- 更新 `scraper.py` 中的 API 端點

### 6.3 錯誤處理

- 使用 try-except 塊捕獲並記錄異常
- 實現重試機制處理臨時網絡問題
- 對於無法解析的頁面，記錄錯誤但繼續處理其他頁面

## 7. 測試計劃

### 7.1 單元測試

- 測試 URL 爬取功能的正確性
- 測試日期比較邏輯的準確性
- 測試解析函數對各類頁面的兼容性

### 7.2 集成測試

- 測試從 URL 爬取到資料存儲的完整流程
- 測試全量更新和增量更新功能
- 測試 API 端點的正確性和可用性

### 7.3 效能測試

- 測試系統在大量評測數據下的表現
- 測試並發請求處理能力
- 測試長時間運行的穩定性

## 8. 交付物

1. 資料庫更新腳本
2. 更新後的爬蟲代碼
3. API 文檔
4. 測試報告
5. 部署和操作說明

## 9. 注意事項

1. 所有爬蟲操作必須遵守目標網站的使用條款
2. 爬蟲應以不干擾網站正常運行為原則
3. 數據僅用於學習和研究目的
4. 應定期檢查目標網站結構變化，及時調整爬蟲代碼

## 10. 術語表

- **GPU**: Graphics Processing Unit，圖形處理器
- **評測 (Review)**: 專業網站對產品進行的測試和評價文章
- **主評測 URL**: 評測的主頁面 URL，包含評測概述和子頁面目錄
- **子頁面 URL**: 評測中特定部分（如電路板分析）的頁面 URL
- **Posted 日期**: 評測發布或更新的日期
- **全量更新**: 重新爬取和處理所有評測資料
- **增量更新**: 只更新自上次爬取後有變化的評測資料
